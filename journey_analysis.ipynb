{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from customer_journey import remove_page_duplicates, remove_pages, group_by\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"user_journey_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Page count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most fundamental metric; it counts how many times each page can be found in all user journeys.\n",
    "def page_count(datafr, target_col='user_journey', subscription='all'):\n",
    "    all_sequences = []\n",
    "    for sequence in datafr[target_col]:\n",
    "        page_list = sequence.split('-')\n",
    "        page_to_count ={}\n",
    "        for page in page_list:\n",
    "            if page not in page_to_count.keys():\n",
    "                page_to_count[page] = 1\n",
    "            else:\n",
    "                page_to_count[page] = page_to_count[page]+1\n",
    "        all_sequences.append(page_to_count)\n",
    "    return all_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page_count(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Page presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts each page only once if it exists in a journey; it shows how many times each page is part of a journey\n",
    "def page_presence(datafr, subscription='all'):\n",
    "    present_pages = []\n",
    "\n",
    "    for dict_ in page_count(datafr):\n",
    "        present_pages.append(list(dict_.keys()))\n",
    "    return present_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page_presence(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Page sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" look at what the most popular run of N pages is. I will consult this metric if Iâ€™m interested in the sequence of\n",
    "three (or any other number) pages that most often show up. Count each sequence only once per journey.\n",
    "\"\"\"\n",
    "def page_sequence(datafr, n_pages:int, top_n:int, target_col='user_journey'):\n",
    "    data_ = group_by(remove_page_duplicates(datafr, target_col))\n",
    "    nested_trunc_tuples = []\n",
    "    for sequence in data_[target_col]:\n",
    "        list_ = sequence.split('-')\n",
    "        # truncate the list_ to n len\n",
    "        # turn the lists into tuples, so they're hashable and can be used with Counter\n",
    "        trunc_list = tuple(list_[:n_pages])\n",
    "        # only return tuples with a min length of n\n",
    "        if len(trunc_list) >= n_pages:\n",
    "            nested_trunc_tuples.append(trunc_list)\n",
    "\n",
    "    counter = Counter(nested_trunc_tuples)\n",
    "    top_most_common = counter.most_common(top_n)\n",
    "    return top_most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Other', 'Other', 'Other', 'Other', 'Other'), 43),\n",
       " (('Other', 'Log in', 'Log in', 'Log in', 'Log in'), 35),\n",
       " (('Other', 'Log in', 'Other', 'Log in', 'Log in'), 6),\n",
       " (('Other', 'Homepage', 'Log in', 'Homepage', 'Log in'), 6),\n",
       " (('Homepage', 'Log in', 'Homepage', 'Log in', 'Homepage'), 5)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_sequence(df, 5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Journey length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the average length of a user's journey in terms of pages, per user session, I assume?\n",
    "def journey_length(datafr, target_col='user_journey'):\n",
    "    journey_lengths = []\n",
    "    for sequence in datafr[target_col]:\n",
    "        list_ = sequence.split('-')\n",
    "        length = len(list_)\n",
    "        journey_lengths.append(length)\n",
    "    return np.mean(journey_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.671363865123302"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journey_length(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "365datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
